{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33e5651",
   "metadata": {},
   "source": [
    "### Document field detection using Template Matching"
   ]
  },
  {
   "cell_type": "raw",
   "id": "861ff3bd",
   "metadata": {},
   "source": [
    "Approach:\n",
    "\n",
    "Clip/Crop field images from the main document and use them as separate templates.\n",
    "Define/tune thresholds for different fields.\n",
    "Apply template matching for each cropped field template using OpenCV function cv2.matchTemplate()\n",
    "Draw bounding boxes using the coordinates of rectangles fetched from template matching.\n",
    "Optional: Augment field templates and fine tune threshold to improve result for different document images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01f6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4df92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 55\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(r'C:\\Users\\2016m\\OneDrive\\Desktop\\Programming\\OpenCV\\cvdata\\tm_joshi.jpg', 0)\n",
    "img0 = image.copy()\n",
    "img1 = cv2.resize(img0, (0,0), fx=0.1, fy=0.1)\n",
    " \n",
    "#Reading the template file\n",
    "template0 = cv2.imread(r'C:\\Users\\2016m\\OneDrive\\Desktop\\Programming\\OpenCV\\cvdata\\tm_joshi_temp.jpg',0)\n",
    "template = cv2.resize(template0, (0,0), fx=0.1, fy=0.1)\n",
    "\n",
    "#width and height of the template file\n",
    "w,h = template.shape[::-1]\n",
    "print(w,h)\n",
    "\n",
    "#list of all methods to apply in for loop\n",
    "methods =  [cv2.TM_CCOEFF , cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR, cv2.TM_CCORR_NORMED , cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]\n",
    "\n",
    "\n",
    "#plt.figure(figsize = (15,15))\n",
    "\n",
    "#looping for each method and showing the plot\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    image = img1.copy()\n",
    "    \n",
    "    #Applying Template Matching\n",
    "    res = cv2.matchTemplate(image , template, method)\n",
    "\n",
    "    #extracting the min_val, max_val, min_loc , max_loc values via minMaxLoc funtion\n",
    "    min_val, max_val, min_loc , max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum else take the max value\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "\n",
    "    bottom_right = (top_left[0]+w , top_left[1]+h)\n",
    "\n",
    "    #Drawing the Rectangle around our probabilistic results\n",
    "    cv2.rectangle(image, top_left, bottom_right , (255,200,0),2)\n",
    "    \n",
    "    cv2.imshow('Output_{}'.format(method), image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fe6ce",
   "metadata": {},
   "source": [
    "#### Face Detection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a4c6ee4",
   "metadata": {},
   "source": [
    "motion detectors are used in many industries, one being the media industry where it is important for the companies to determine the public reaction to their products. In this article, we are going to build a smile detector using OpenCV which takes in live feed from webcam. The smile/happiness detector that we are going to implement would be a raw one, there exist many better ways to implement it.\n",
    "\n",
    "Step # 1: First of all, we need to import the OpenCV library. \n",
    "Step #2: Include the desired haar-cascades.\n",
    "Step #3: In this step, we are going to build main function which would be performing the smile detection. \n",
    "Step #4: We define main function in this step. After execution, the function can be terminated by pressing the “q” key. \n",
    " \n",
    " \n",
    "Link to download cascade data : https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "547362f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Intiating the smile_cascade Classifier\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "\n",
    "        #Detecting the faces in the image\n",
    "        faces = smile_cascade.detectMultiScale(image, 1.2, 4)\n",
    "\n",
    "        #Drawing rectangles on the faces detected\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(image, (x,y), (x+w , y+h), (255,0,0), 2)\n",
    "\n",
    "        cv2.imshow(\"Detection_face\", image)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):              \n",
    "            break\n",
    "except:\n",
    "    print(\"There seems to be a error : Check Camera\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4418d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641b67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
